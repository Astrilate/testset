# testset
1. CNN相关以及基础知识
1.1 核心内容
- 卷积神经网络是一种深度学习模型，能够自动地从数据中学习特征，它在计算机视觉领域中广泛用于图像处理任务，如图像分类、目标检测和图像分割。核心思想是利用卷积层来提取特征，利用池化层来降维特征，然后通过全连接层进行分类、回归等任务
卷积神经网络的优势：
    - 局部卷积：对图像进行局部感知，利用到了数据的局部结构和特征的层次性（ps: 全连接神经网络是进行全局感知）
    - 参数共享：网络中的同一卷积层中，不同位置之间使用相同的权重参数，像卷积核或滤波器。比如卷积核在整个输入数据上的不同位置使用相同的权重，这个权重在整张图上是共享的。这样可以更有效地捕捉图像中的局部特征，并且减少了需要学习的参数数量
    - 相比全连接：全连接参数量更加庞大，容易过拟合，并且对于图像的平移旋转等变化处理不够理想。cnn通过卷积池化等步骤可以在捕捉局部特征的同时，保留空间结构，具有更好的泛化性
---
1.2 CNN中的操作
1.2.1 卷积层
- 通过卷积核或过滤器的矩阵在输入图像中滑动计算，卷积核的权重与图像上的对应区域的像素值相乘，然后将所有乘积结果相加，来提取局部特征，最常见的比如边缘，纹理等，下图代码展示的是最简单的卷积核提取图像的边缘任务
from matplotlib import pyplot as plt
import cv2
import numpy as np  
Image = plt.imread("./image.jpg")
filter = np.array([
  [-1, -1, -1],
  [-1,  8, -1],
  [-1, -1, -1]
])  # 提取边缘的卷积核
result = cv2.filter2D(image, -1, filter)
plt.imshow(result)
plt.show()  # 展示结果
- 边缘提取：当这个卷积核滑过一个图像上的区域时，如果该区域包含一个边缘，则说明在一个相对小的区域内，像素值会从暗变亮或者从亮变暗，那么对应的像素值变化将在卷积操作中会产生一个较大的响应。这就是为什么在中心元素为8的位置，卷积核能够增强边缘的原因
self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1, stride=1)
- 卷积层：以上代码为cnn卷积层，kernel_size为卷积核大小，stride为卷积核在输入数据上移动的步长，影响特征图输出的大小；padding是在输入数据周围添加像素，以便保持输出尺寸与输入尺寸符合。对于 input_channels，RGB彩色图像一般情况下是三维的，输入通道数为3，而灰度图像输入通道数为1，卷积时采用多通道卷积，结果按通道相加获得输出
---
1.2.2 池化层
- 池化操作用于减小特征图的尺寸并保留重要信息，从而减少计算量，减少运行时内存的占用，并增强模型的鲁棒性。其中，池化包括最大池化和平均池化，分别是选取每个窗口的最大值和平均值输出
input_tensor = torch.tensor([[[
        [1.0, 2.0, 3.0, 4.0],
        [5.0, 6.0, 7.0, 8.0],
        [9.0, 10.0, 11.0, 12.0],
        [13.0, 14.0, 15.0, 16.0]
]]])
pool = nn.MaxPool2d(kernel_size=2, stride=2)
output_tensor = pool(input_tensor)
print(output_tensor)
# tensor([[[[ 6.,  8.],
#           [14., 16.]]]])
- 下采样：池化操作的参数主要包括kernel_size和stride。较大的池化窗口会减小特征图尺寸更快，而较小的池化窗口可以保留更多细节。比如像上面这行代码进行的是对四维向量（且为浮点数据）的2x2的最大池化，也可使用padding来填充，要注意的是若行数列数不够则多出的行列不会进行最大池化，也不会输出。通常池化层也作为cnn网络中下采样的操作，使特征图的大小逐级减半，同样可以进行下采样操作的还有卷积层，调整kernel_size和stride也可以实现下采样
1.2.3 激活函数
1.2.4 批量归一化
1.3 损失函数和优化器
1.4 迁移学习和预训练模型
1.5 一些常见的卷积神经网络结构
时间流的输入是光流，光流捕捉运动信息特征，前后两帧得到一张光流的图，L帧的视频得到L-1张光流图，每个像素点对应光流值，代表运动幅度。视频等间距抽取25帧，对于空间流（也是做图像分类），对图片处理后送入空间流神经网络，对最终结果取平均得到预测；对于时间流，先往后取11帧，在11帧中抽取光流，并把光流图送到空间神经网络，对最后结果去平均。最后对两个神经网络的结果做late fusion，得到最终结果。
---
2. 过拟合处理
- 过拟合作为我在训练cnn网络时卡测试集准确率的首要元凶，我觉得很有必要单独地专门整理一下处理对策。虽说过拟合处理方法很多，但是以下为本次切实对cifar100图像分类任务有用的方法，以及一些运行中发现的注意事项
2.1 dropout层
2.2 L1/L2正则化
L2正则化：
L1正则化：
2.3 数据增强/扩充
2.4 降低模型复杂度
2.5 batchsize/学习率?
---
3. RNN相关
3.1 核心内容
3.2 LSTM网络
